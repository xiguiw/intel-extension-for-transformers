:orphan:

:py:mod:`intel_extension_for_transformers.neural_chat.pipeline.plugins.video.face_animation.src.facerender.sync_batchnorm.batchnorm`
====================================================================================================================================

.. py:module:: intel_extension_for_transformers.neural_chat.pipeline.plugins.video.face_animation.src.facerender.sync_batchnorm.batchnorm


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   intel_extension_for_transformers.neural_chat.pipeline.plugins.video.face_animation.src.facerender.sync_batchnorm.batchnorm.SynchronizedBatchNorm1d
   intel_extension_for_transformers.neural_chat.pipeline.plugins.video.face_animation.src.facerender.sync_batchnorm.batchnorm.SynchronizedBatchNorm2d
   intel_extension_for_transformers.neural_chat.pipeline.plugins.video.face_animation.src.facerender.sync_batchnorm.batchnorm.SynchronizedBatchNorm3d




.. py:class:: SynchronizedBatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True)




   Applies Synchronized Batch Normalization over a 2d or 3d input that is seen as a
   mini-batch.

   .. math::

       y = \frac{x - mean[x]}{ \sqrt{Var[x] + \epsilon}} * gamma + beta

   This module differs from the built-in PyTorch BatchNorm1d as the mean and
   standard-deviation are reduced across all devices during training.

   For example, when one uses `nn.DataParallel` to wrap the network during
   training, PyTorch's implementation normalize the tensor on each device using
   the statistics only on that device, which accelerated the computation and
   is also easy to implement, but the statistics might be inaccurate.
   Instead, in this synchronized version, the statistics will be computed
   over all training samples distributed on multiple devices.

   Note that, for one-GPU or CPU-only case, this module behaves exactly same
   as the built-in PyTorch implementation.

   The mean and standard-deviation are calculated per-dimension over
   the mini-batches and gamma and beta are learnable parameter vectors
   of size C (where C is the input size).

   During training, this layer keeps a running estimate of its computed mean
   and variance. The running sum is kept with a default momentum of 0.1.

   During evaluation, this running mean/variance is used for normalization.

   Because the BatchNorm is done over the `C` dimension, computing statistics
   on `(N, L)` slices, it's common terminology to call this Temporal BatchNorm

   :param num_features: num_features from an expected input of size
                        `batch_size x num_features [x width]`
   :param eps: a value added to the denominator for numerical stability.
               Default: 1e-5
   :param momentum: the value used for the running_mean and running_var
                    computation. Default: 0.1
   :param affine: a boolean value that when set to ``True``, gives the layer learnable
                  affine parameters. Default: ``True``

   Shape:
       - Input: :math:`(N, C)` or :math:`(N, C, L)`
       - Output: :math:`(N, C)` or :math:`(N, C, L)` (same shape as input)

   .. rubric:: Examples

   >>> # With Learnable Parameters
   >>> m = SynchronizedBatchNorm1d(100)
   >>> # Without Learnable Parameters
   >>> m = SynchronizedBatchNorm1d(100, affine=False)
   >>> input = torch.autograd.Variable(torch.randn(20, 100))
   >>> output = m(input)


.. py:class:: SynchronizedBatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True)




   Applies Batch Normalization over a 4d input that is seen as a mini-batch
   of 3d inputs

   .. math::

       y = \frac{x - mean[x]}{ \sqrt{Var[x] + \epsilon}} * gamma + beta

   This module differs from the built-in PyTorch BatchNorm2d as the mean and
   standard-deviation are reduced across all devices during training.

   For example, when one uses `nn.DataParallel` to wrap the network during
   training, PyTorch's implementation normalize the tensor on each device using
   the statistics only on that device, which accelerated the computation and
   is also easy to implement, but the statistics might be inaccurate.
   Instead, in this synchronized version, the statistics will be computed
   over all training samples distributed on multiple devices.

   Note that, for one-GPU or CPU-only case, this module behaves exactly same
   as the built-in PyTorch implementation.

   The mean and standard-deviation are calculated per-dimension over
   the mini-batches and gamma and beta are learnable parameter vectors
   of size C (where C is the input size).

   During training, this layer keeps a running estimate of its computed mean
   and variance. The running sum is kept with a default momentum of 0.1.

   During evaluation, this running mean/variance is used for normalization.

   Because the BatchNorm is done over the `C` dimension, computing statistics
   on `(N, H, W)` slices, it's common terminology to call this Spatial BatchNorm

   :param num_features: num_features from an expected input of
                        size batch_size x num_features x height x width
   :param eps: a value added to the denominator for numerical stability.
               Default: 1e-5
   :param momentum: the value used for the running_mean and running_var
                    computation. Default: 0.1
   :param affine: a boolean value that when set to ``True``, gives the layer learnable
                  affine parameters. Default: ``True``

   Shape:
       - Input: :math:`(N, C, H, W)`
       - Output: :math:`(N, C, H, W)` (same shape as input)

   .. rubric:: Examples

   >>> # With Learnable Parameters
   >>> m = SynchronizedBatchNorm2d(100)
   >>> # Without Learnable Parameters
   >>> m = SynchronizedBatchNorm2d(100, affine=False)
   >>> input = torch.autograd.Variable(torch.randn(20, 100, 35, 45))
   >>> output = m(input)


.. py:class:: SynchronizedBatchNorm3d(num_features, eps=1e-05, momentum=0.1, affine=True)




   Applies Batch Normalization over a 5d input that is seen as a mini-batch
   of 4d inputs

   .. math::

       y = \frac{x - mean[x]}{ \sqrt{Var[x] + \epsilon}} * gamma + beta

   This module differs from the built-in PyTorch BatchNorm3d as the mean and
   standard-deviation are reduced across all devices during training.

   For example, when one uses `nn.DataParallel` to wrap the network during
   training, PyTorch's implementation normalize the tensor on each device using
   the statistics only on that device, which accelerated the computation and
   is also easy to implement, but the statistics might be inaccurate.
   Instead, in this synchronized version, the statistics will be computed
   over all training samples distributed on multiple devices.

   Note that, for one-GPU or CPU-only case, this module behaves exactly same
   as the built-in PyTorch implementation.

   The mean and standard-deviation are calculated per-dimension over
   the mini-batches and gamma and beta are learnable parameter vectors
   of size C (where C is the input size).

   During training, this layer keeps a running estimate of its computed mean
   and variance. The running sum is kept with a default momentum of 0.1.

   During evaluation, this running mean/variance is used for normalization.

   Because the BatchNorm is done over the `C` dimension, computing statistics
   on `(N, D, H, W)` slices, it's common terminology to call this Volumetric BatchNorm
   or Spatio-temporal BatchNorm

   :param num_features: num_features from an expected input of
                        size batch_size x num_features x depth x height x width
   :param eps: a value added to the denominator for numerical stability.
               Default: 1e-5
   :param momentum: the value used for the running_mean and running_var
                    computation. Default: 0.1
   :param affine: a boolean value that when set to ``True``, gives the layer learnable
                  affine parameters. Default: ``True``

   Shape:
       - Input: :math:`(N, C, D, H, W)`
       - Output: :math:`(N, C, D, H, W)` (same shape as input)

   .. rubric:: Examples

   >>> # With Learnable Parameters
   >>> m = SynchronizedBatchNorm3d(100)
   >>> # Without Learnable Parameters
   >>> m = SynchronizedBatchNorm3d(100, affine=False)
   >>> input = torch.autograd.Variable(torch.randn(20, 100, 35, 45, 10))
   >>> output = m(input)


