:orphan:

:py:mod:`intel_extension_for_transformers.transformers.ppo_config`
==================================================================

.. py:module:: intel_extension_for_transformers.transformers.ppo_config


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   intel_extension_for_transformers.transformers.ppo_config.PPOConfig




.. py:class:: PPOConfig


   Configuration class for PPOTrainer

   .. py:attribute:: exp_name
      :type: str

      the name of this experiment (by default is the file name without the extension name)

   .. py:attribute:: seed
      :type: int
      :value: 0

      Seed value for random generations

   .. py:attribute:: log_with
      :type: Optional[Literal[wandb, tensorboard]]

      //huggingface.co/docs/accelerate/usage_guides/tracking
      for more details

      :type: Log with either 'wandb' or 'tensorboard', check  https

   .. py:attribute:: task_name
      :type: Optional[str]

      Name of task to use - used only for tracking purposes

   .. py:attribute:: model_name
      :type: Optional[str]

      Name of model to use - used only for tracking purposes

   .. py:attribute:: query_dataset
      :type: Optional[str]

      Name of dataset to query - used only for tracking purposes

   .. py:attribute:: reward_model
      :type: Optional[str]

      The reward model to use - used only for tracking purposes

   .. py:attribute:: remove_unused_columns
      :type: bool
      :value: True

      Remove unused columns from the dataset if `datasets.Dataset` is used

   .. py:attribute:: tracker_kwargs
      :type: JSONDict

      {"entity":
      "my_wandb_entity", "name": "my_exp_name"}}'

      :type: Keyword arguments for the tracker (e.g. python ppo.py --ppo_config.tracker_kwargs='{"wandb"

   .. py:attribute:: accelerator_kwargs
      :type: JSONDict

      Keyword arguments for the accelerator

   .. py:attribute:: project_kwargs
      :type: JSONDict

      Keyword arguments for the accelerator project config (e.g. `logging_dir`)

   .. py:attribute:: tracker_project_name
      :type: str
      :value: 'trl'

      Name of project to use for tracking

   .. py:attribute:: push_to_hub_if_best_kwargs
      :type: JSONDict

      Keyword arguments for pushing model to the hub during training (e.g. repo_id)

   .. py:attribute:: steps
      :type: int
      :value: 20000

      Number of training steps

   .. py:attribute:: learning_rate
      :type: float
      :value: 1e-05

      Adam learning rate

   .. py:attribute:: adap_kl_ctrl
      :type: bool
      :value: True

      Use adaptive KL control, otherwise linear

   .. py:attribute:: init_kl_coef
      :type: Optional[float]
      :value: 0.2

      Initial KL penalty coefficient (used for adaptive and linear control)

   .. py:attribute:: kl_penalty
      :type: Literal[kl, abs, mse, full]
      :value: 'kl'

      model_logp - ref_logp,  'abs': abs(kl),  'mse': mean squared error mse(kl) and 'full':
      the actual kl for all tokens in the distribution

      :type: kl penalty options

      :type: 'kl'

   .. py:attribute:: target
      :type: Optional[float]
      :value: 6

      Target KL value for adaptive KL control

   .. py:attribute:: horizon
      :type: Optional[float]
      :value: 10000

      Horizon for adaptive KL control

   .. py:attribute:: gamma
      :type: float
      :value: 1

      Gamma parameter for advantage calculation

   .. py:attribute:: lam
      :type: float
      :value: 0.95

      Lambda parameter for advantage calculation

   .. py:attribute:: cliprange
      :type: float
      :value: 0.2

      Range for clipping in PPO policy gradient loss

   .. py:attribute:: cliprange_value
      :type: float
      :value: 0.2

      Range for clipping values in loss calculation

   .. py:attribute:: vf_coef
      :type: float
      :value: 0.1

      Scaling factor for value loss

   .. py:attribute:: batch_size
      :type: int
      :value: 256

      Number of samples per optimisation step

   .. py:attribute:: mini_batch_size
      :type: int
      :value: 1

      Number of samples optimized in each mini batch

   .. py:attribute:: gradient_accumulation_steps
      :type: int
      :value: 1

      The number of gradient accumulation steps

   .. py:attribute:: world_size
      :type: tyro.conf.Suppress[int]

      The world size for distributed training

   .. py:attribute:: ppo_epochs
      :type: int
      :value: 4

      Number of optimisation epochs per batch of samples

   .. py:attribute:: max_grad_norm
      :type: Optional[float]

      Maximum gradient norm for gradient clipping

   .. py:attribute:: optimize_device_cache
      :type: Optional[bool]
      :value: False

      Optimize device cache for slightly more memory-efficient training

   .. py:attribute:: early_stopping
      :type: bool
      :value: False

      Whether to stop the PPO optimization loop early is the KL too high

   .. py:attribute:: target_kl
      :type: float
      :value: 1

      Stop early if we exceed this value by over 50%

   .. py:attribute:: compare_steps
      :type: int
      :value: 1

      Number of steps between comparison of the current reward with the best seen so far

   .. py:attribute:: ratio_threshold
      :type: float
      :value: 10.0

      Skip mini-batches with high PPO ratios that can cause loss spikes

   .. py:attribute:: use_score_scaling
      :type: bool
      :value: False

      Use score scaling

   .. py:attribute:: use_score_norm
      :type: bool
      :value: False

      Use score normalization. Only applicable if use_score_scaling is True

   .. py:attribute:: score_clip
      :type: Optional[float]

      Score clipping

   .. py:attribute:: whiten_rewards
      :type: bool
      :value: False

      Whiten the rewards before compute advantages

   .. py:attribute:: is_encoder_decoder
      :type: Optional[tyro.conf.Suppress[bool]]

      Whether the model is an encoder-decoder model

      :type: TO BE FILLED In RUNTIME

   .. py:attribute:: is_peft_model
      :type: Optional[tyro.conf.Suppress[bool]]

      Whether the model is a PEFT model

      :type: TO BE FILLED In RUNTIME

   .. py:attribute:: backward_batch_size
      :type: tyro.conf.Suppress[int]

      Number of samples optimized in an `optimizer.step()` call

      :type: TO BE FILLED In RUNTIME

   .. py:attribute:: global_backward_batch_size
      :type: tyro.conf.Suppress[int]

      the effective `backward_batch_size` across all processes

      :type: TO BE FILLED In RUNTIME

   .. py:attribute:: global_batch_size
      :type: tyro.conf.Suppress[int]

      the effective `batch_size` across all processes

      :type: TO BE FILLED In RUNTIME

   .. py:attribute:: use_habana
      :type: bool
      :value: False

      Use habana. Only applicable if use_habana is True

   .. py:attribute:: pad_for_acceleration
      :type: bool
      :value: False

      Use pad_for_acceleration. Only applicable if pad_for_acceleration is True

   .. py:attribute:: pad_max_len
      :type: int
      :value: 0

      Use pad_for_acceleration. Only applicable if pad_for_acceleration is True


