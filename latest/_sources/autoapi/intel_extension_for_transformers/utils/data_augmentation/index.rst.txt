:py:mod:`intel_extension_for_transformers.utils.data_augmentation`
==================================================================

.. py:module:: intel_extension_for_transformers.utils.data_augmentation

.. autoapi-nested-parse::

   Data augmentation API.

   Please refer to https://github.com/intel/intel-extension-for-transformers/blob/main/docs/data_augmentation.md.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   intel_extension_for_transformers.utils.data_augmentation.DataAugmentation




.. py:class:: DataAugmentation(augmenter_type: str)


   DataAugmentation provides many ways to enhance existing datasets.

   :param augmenter_type: augmenter type like: "TextGenerationAug", "KeyboardAug", ...
   :type augmenter_type: string

   Example::

       aug = DataAugmentation(augmenter_type="TextGenerationAug")
       aug.input_dataset = self.origin_data
       aug.output_path = os.path.join(self.result_path, "test1.cvs")
       aug.augmenter_arguments = {'model_name_or_path': 'gpt2-medium'}
       aug.data_augment()

   .. py:method:: data_augment()

      Execute the process of data augmentation.


   .. py:method:: text_generation_augmentation(extension, raw_datasets)

      Execute the process of text generation augmentation.

              Args:
                  extension: No used
                  raw_datasets: The original datasets, the datasets can be from huggingface datasets(like: glue/sst2) or
                  the customer datasets, each sample should be:
                      'label' + '     ' + 'sentence' + EOS + '
      '

              augmenter_arguments for text generation augmentation::

                  {'model_name_or_path': 'gpt2',"              'k': 0, // top_k, default: 0
                   'p': 0.9, // top_p, default: 0.9
                   'temperature': 1.0, // temperature of 1.0 has no effect,
                                       // lower tend toward greedy sampling, default: 1.0
                   'repetition_penalty': 1.0, // primarily useful for CTRL model, default: 1.0
                   'num_return_sentences': -1 // number of sentences to generate. default is -1 means the entire dataset
                   'num_samples': 1, // number of samples generated by each conditional text
                                     // generation run. default: 1
                   'stop_token': EOS // end of sentence token, at which text generation is stopped.
                                    // default: EOS
                  }



   .. py:method:: mit_data_augmentation(extension, raw_datasets)

      Execute the process of nlpaug data augmentation.

      nlpaug is the library helps you with augmenting nlp for your machine learning projects.
      It provide many augmenter, please refer to: https://github.com/makcedward/nlpaug#augmenter.

      :param extension: Suffix name of the original dataset file, now only support "csv" and "json".
      :type extension: str
      :param raw_datasets: original datasets, like:label + '      ' + sentence.
                           user should set column_names if the sample contains multiple sentences:
                               aug.column_names = ['sentence1', 'sentence2'].
      :type raw_datasets: dict



